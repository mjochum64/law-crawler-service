# Legal Document Crawler Service

Ein containerisierter Spring Boot Service zum Crawlen von Rechtsprechung, Gesetzen und Verwaltungsvorschriften von https://www.rechtsprechung-im-internet.de

## ğŸš€ Features

- **ğŸ³ Docker-basiertes Setup** mit vollstÃ¤ndiger Container-Orchestrierung
- **ğŸ” Apache Solr Integration** fÃ¼r performante Volltextsuche
- **ğŸ“ Duale Speicherung** - XML-Dateien + Solr-Index fÃ¼r beste FlexibilitÃ¤t  
- **âš¡ Intelligente Sitemap-Discovery** mit Gzip-UnterstÃ¼tzung
- **ğŸš¦ Rate Limiting** und ethisches Crawling
- **ğŸ“… Scheduling** fÃ¼r automatisierte Crawling-Sessions
- **ğŸŒ REST API** fÃ¼r Steuerung und Monitoring
- **ğŸ“Š Nginx Reverse Proxy** mit Load Balancing
- **ğŸ”§ Comprehensive Health Checks** und Monitoring

## ğŸ›ï¸ UnterstÃ¼tzte Gerichte

- **BAG** - Bundesarbeitsgericht
- **BGH** - Bundesgerichtshof  
- **BSG** - Bundessozialgericht
- **BVerwG** - Bundesverwaltungsgericht

## ğŸ“‹ Voraussetzungen

- **Docker & Docker Compose** (empfohlen)
- Alternativ: Java 17+ und Maven 3.8+

## ğŸš€ Quick Start mit Docker

```bash
# Repository klonen
git clone <repository-url>
cd law-crawler-service

# Komplettes System starten (Solr + Crawler + Nginx)
docker-compose up -d

# Logs verfolgen
docker-compose logs -f

# System stoppen
docker-compose down
```

**ğŸ¯ Nach dem Start verfÃ¼gbar:**
- **API:** http://localhost:8080
- **Nginx Gateway:** http://localhost:8888  
- **Solr Admin:** http://localhost:8983/solr
- **Grafana Dashboards:** http://localhost:3000 (admin/admin123)
- **Prometheus Metrics:** http://localhost:9090

## ğŸ—ï¸ Architektur

```
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   Prometheus    â”‚    â”‚     Grafana     â”‚
                    â”‚   Metrics       â”‚â—„â”€â”€â–ºâ”‚   Dashboards    â”‚
                    â”‚   Port 9090     â”‚    â”‚   Port 3000     â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â–²                      â–²
                              â”‚                      â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     Nginx       â”‚    â”‚  Spring Boot    â”‚    â”‚   Apache Solr   â”‚
â”‚  Reverse Proxy  â”‚â—„â”€â”€â–ºâ”‚   Crawler App   â”‚â—„â”€â”€â–ºâ”‚   Search Index  â”‚
â”‚   Port 8888     â”‚    â”‚    Port 8080    â”‚    â”‚   Port 8983     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
                       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                       â”‚  XML File Store â”‚    â”‚  Loki + Promtailâ”‚
                       â”‚ /app/data/legal â”‚    â”‚   Log Pipeline  â”‚
                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ğŸ” Monitoring Stack
- **Prometheus**: Metrics collection (JVM, HTTP, Tomcat, Business metrics)
- **Grafana**: 3 Dashboards - System, Business, Logs
- **Loki + Promtail**: Log aggregation and real-time analysis
- **Health Checks**: Application and container-level monitoring

## ğŸ”§ Konfiguration

### Docker Profile (Standard)
```yaml
# application-docker.yml
crawler:
  storage:
    type: solr
    base-path: /app/data/legal-documents
  solr:
    url: http://solr:8983/solr
    collection: legal-documents
```

### Umgebungsvariablen
```bash
SPRING_PROFILES_ACTIVE=docker,solr
SOLR_URL=http://solr:8983/solr
SOLR_COLLECTION=legal-documents
JAVA_OPTS=-Xms512m -Xmx2g -XX:+UseG1GC
```

## ğŸŒ REST API

### ğŸ•·ï¸ Crawling starten
```bash
# Einzeldatum crawlen
POST http://localhost:8080/api/crawler/crawl?date=2025-01-15

# Mit Force-Update
POST http://localhost:8080/api/crawler/crawl?date=2025-01-15&forceUpdate=true
```

### ğŸ“Š Status abfragen
```bash
GET http://localhost:8080/api/crawler/status
# Response: {"totalDocuments":1247,"downloadedDocuments":1247,"pendingDocuments":0,...}
```

### ğŸ” Dokumente suchen
```bash
GET http://localhost:8080/api/crawler/search?query=arbeitsrecht
```

### ğŸ›ï¸ Dokumente nach Gericht
```bash
GET http://localhost:8080/api/crawler/documents/BAG?page=0&size=20
```

### ğŸ§ª Sitemap-Optimierungen testen
```bash
GET http://localhost:8080/api/crawler/test/sitemap-optimizations
# Response: {"summary":"Tested 10 dates: 10 exist, 0 gzipped, 10 with content",...}
```

### ğŸ”„ Fehlgeschlagene Downloads wiederholen
```bash
POST http://localhost:8080/api/crawler/retry-failed
```

## ğŸ“ Speicherstruktur

### Container-Volumes
```bash
# XML-Dateien (persistent)
crawler_data:/app/data/legal-documents/

# Log-Dateien (persistent)  
crawler_logs:/app/logs/

# Solr-Daten (persistent)
solr_data:/var/solr/data/
```

### Dateiorganisation
```
/app/data/legal-documents/
â”œâ”€â”€ bag/          # Bundesarbeitsgericht
â”‚   â”œâ”€â”€ 2025/
â”‚   â”‚   â”œâ”€â”€ 01/   # Januar
â”‚   â”‚   â””â”€â”€ 02/   # Februar  
â”œâ”€â”€ bgh/          # Bundesgerichtshof
â”œâ”€â”€ bsg/          # Bundessozialgericht
â””â”€â”€ bverwg/       # Bundesverwaltungsgericht
```

## ğŸ”„ Container-Management

### Status prÃ¼fen
```bash
docker-compose ps
docker-compose logs crawler-app
docker-compose logs solr
```

### Einzelne Services neustarten
```bash
docker-compose restart crawler-app
docker-compose restart solr
docker-compose restart nginx
```

### Solr-Daten zurÃ¼cksetzen
```bash
# Alle Dokumente aus Solr lÃ¶schen
curl -X POST "http://localhost:8983/solr/legal-documents/update?commit=true" \
     -H "Content-Type: text/xml" \
     --data-binary "<delete><query>*:*</query></delete>"
```

### Kompletter Reset
```bash
# Alle Container und Volumes lÃ¶schen
docker-compose down -v

# Neu starten  
docker-compose up -d
```

## â° Automatisierung

### Aktive Cron-Jobs
- **TÃ¤glich 6:00 Uhr**: Crawling der letzten 7 Tage
- **Sonntags 2:00 Uhr**: VollstÃ¤ndiger Crawl der letzten 30 Tage
- **Alle 6 Stunden**: Wiederholung fehlgeschlagener Downloads
- **StÃ¼ndlich**: System Health Check

## ğŸ“Š Monitoring & Health Checks

### Container Health Checks
```bash
# Crawler App Health
curl http://localhost:8080/actuator/health

# Solr Health
curl http://localhost:8983/solr/legal-documents/admin/ping

# Nginx Status
curl http://localhost:8888
```

### Actuator Endpoints
- **Health:** http://localhost:8080/actuator/health
- **Metrics:** http://localhost:8080/actuator/metrics  
- **Info:** http://localhost:8080/actuator/info
- **Solr Stats:** http://localhost:8080/actuator/solr

### Solr Admin UI
- **URL:** http://localhost:8983/solr
- **Collection:** legal-documents
- **Query Console:** http://localhost:8983/solr/#/legal-documents/query

## ğŸ§ª Entwicklung & Tests

### Lokale Entwicklung
```bash
# Nur Solr starten fÃ¼r lokale Entwicklung
docker-compose up -d solr

# App lokal starten
SPRING_PROFILES_ACTIVE=solr mvn spring-boot:run
```

### Tests ausfÃ¼hren
```bash
# Unit Tests
mvn test

# Mit Integration Tests
mvn verify

# Coverage Report
mvn jacoco:report
```

### Build ohne Docker
```bash
mvn clean package
java -jar target/law-crawler-service-1.0.0-SNAPSHOT.jar
```

## ğŸ”§ Technologie-Stack

### ğŸ—ï¸ Backend
- **Spring Boot 3.2.2** - Application Framework
- **Java 17** - Runtime Environment  
- **Apache Solr 9.4.1** - Search Engine
- **Spring Data** - Data Access Layer
- **Quartz Scheduler** - Cron Jobs

### ğŸ³ Infrastructure  
- **Docker & Docker Compose** - Containerization
- **Nginx** - Reverse Proxy & Load Balancer
- **Eclipse Temurin 17** - JVM Runtime

### ğŸ“¦ Libraries
- **SolrJ** - Solr Java Client
- **Jetty HTTP Client** - HTTP Communications
- **JSoup** - HTML/XML Parsing
- **Apache HttpComponents** - HTTP Client

## ğŸš¨ Troubleshooting

### ğŸ” HÃ¤ufige Probleme

#### 1. Container starten nicht
```bash
# Logs prÃ¼fen
docker-compose logs

# Ports prÃ¼fen
netstat -tulpn | grep -E ':(8080|8983|8888)'

# Volumes zurÃ¼cksetzen
docker-compose down -v && docker-compose up -d
```

#### 2. Solr Connection Failed
```bash
# Solr Health prÃ¼fen
curl http://localhost:8983/solr/admin/ping

# Container Networking prÃ¼fen
docker-compose exec crawler-app ping solr
```

#### 3. ClassCastException in Logs
```bash
# Fixed in current version - update to latest image
docker-compose build crawler-app
docker-compose up -d
```

#### 4. Jetty Client Errors
```bash
# Dependencies werden automatisch installiert
# Bei Problemen: Image neu bauen
docker-compose build --no-cache crawler-app
```

### ğŸ“‹ Debug-Befehle
```bash
# Container Shell
docker-compose exec crawler-app bash
docker-compose exec solr bash

# Live-Logs
docker-compose logs -f crawler-app

# Resource-Verbrauch
docker stats
```

## âš–ï¸ Rechtliche Hinweise

- **âœ… Respektiert robots.txt** der Zielwebseite
- **ğŸš¦ Rate Limiting** implementiert (2 Sekunden zwischen Requests)
- **ğŸŒ Nur Ã¶ffentlich verfÃ¼gbare** Dokumente
- **âš ï¸ Keine rechtliche Beratung** durch diesen Service

## ğŸ¤ Beitragen

1. **Fork** des Repositories erstellen
2. **Feature Branch** erstellen (`git checkout -b feature/amazing-feature`)
3. **Tests** hinzufÃ¼gen und prÃ¼fen (`mvn test`)
4. **Docker Build** testen (`docker-compose build`)
5. **Pull Request** erstellen

## ğŸ“„ Lizenz

Dieses Projekt steht unter der [MIT Lizenz](LICENSE).

---

**ğŸš€ Powered by Docker, Spring Boot & Apache Solr**