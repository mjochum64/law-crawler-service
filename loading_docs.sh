#!/bin/bash
# full-crawl.sh - VollstÃ¤ndiges Crawling aller verfÃ¼gbaren Dokumente

echo "ğŸš€ Starte vollstÃ¤ndiges Crawling aller verfÃ¼gbaren Dokumente..."

START_DATE="2025-07-01"  # Startdatum der Website
END_DATE=$(date -I)      # Heute

current_date=$START_DATE
total_days=$(( ( $(date -d "$END_DATE" +%s) - $(date -d "$START_DATE" +%s) ) / 86400 ))
day_count=0

echo "ğŸ“… Crawling Zeitraum: $START_DATE bis $END_DATE ($total_days Tage)"

while [ "$current_date" != $(date -I -d "$END_DATE + 1 day") ]; do
    day_count=$((day_count + 1))
    progress=$((day_count * 100 / total_days))

    echo "ğŸ“Š Progress: $progress% - Tag $day_count/$total_days - Datum: $current_date"

    # Crawl fÃ¼r aktuelles Datum
    response=$(curl -s -X POST "http://localhost:8080/api/crawler/crawl?date=$current_date")

    if echo "$response" | grep -q "successfully"; then
        echo "âœ… $current_date: Erfolgreich gestartet"
    else
        echo "âš ï¸ $current_date: MÃ¶glicherweise keine Dokumente verfÃ¼gbar"
    fi

    # Status alle 10 Tage Ã¼berprÃ¼fen
    if [ $((day_count % 10)) -eq 0 ]; then
        echo "ğŸ“ˆ Zwischenstatus:"
        curl -s "http://localhost:8080/api/crawler/status" | jq '.totalDocuments, .downloadedDocuments, .failedDocuments'
    fi

    # Rate limiting - 30 Sekunden Pause
    sleep 30

    current_date=$(date -I -d "$current_date + 1 day")
done

  echo "ğŸ‰ VollstÃ¤ndiges Crawling abgeschlossen!"
  curl "http://localhost:8080/api/crawler/status"
